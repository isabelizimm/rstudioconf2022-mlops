---
format: 
    revealjs:
        slide-number: true
        theme: [default, style.scss]
        logo: images/vetiverhex.png
        width: 1600
        height: 900
---
##

::: {style="position: absolute; left: 480px; top: 200px; height: 525px; width: 1500px; background-color: #f3cbac; padding: 20px; padding-left: 50px; box-shadow: 15px 15px 0px 0px #a46848; border-radius: 5px;"}
[Demystifying MLOps]{style="font-size: 120px; font-weight: bold; line-height: 1em; margin: 0px"}

<br>

[Isabel Zimmerman, RStudio PBC]{style="font-size: 60px; font-weight: bold;"}

[rstudio::conf(2022)]{style="font-size: 50px;font-weight: bold;"}
:::

::: {.notes}
im here to dymystgy mlops because machine learning operations are HARD i spent a lot of time with deploying models,,,

more importantly I LOVE BAKING
:::

##

![](images/happy.jpg){height="700" margin-left="700" margin-right="auto"}

::: {.notes}
machine learning models are like chocolate chips...

while model development occurs in notebooks, the value of models often comes when they are integrated into a larger system
:::

## what is MLOps?

set of <u>practices</u> to _deploy_ and _maintain_ machine learning models in production **reliably** and **efficiently**

::: {.notes}
what are some MLOps practices?
:::

##

![](./images/evolution_of_cookie.png)

::: {.notes}
- write down our recipe
- baking the dough
- making changes when things don't go as planned
:::

##

![](./images/ml_ops_cycle.png)

::: {.notes}
- version
- deploy
- monitor

now, let's pause here for a moment-- MLOps is not a disjoint piece where data scientists can pass off models to IT, or whoever handles deployment. MLOps is part of the data science lifecycle.

There are lots of tools for the righthand side of this image--if you were just at Julia and Max's keynote, this might look familiar. Well, mostly familiar.
:::


## version
_how do we track and manage change?_

![](./images/recipe_card.png)

::: {.notes}
try different flours, using salted or unsalted butter,
:::

## version

`model`

::: {.notes}
now, i have a quick cautionary tale for you all on what happens when you don't version your model.
:::

## version

`model`

. . .

`model_final`

. . .

`model_final_ACTUALLY`

. . .

`model_final_ACTUALLY_1`

::: {.notes}
lacks context
not scalable
:::
   
## version

versioning is useful to track changes across _time_, but it should also be for **different implementations**

::: {.notes}
and this is not a new idea! most developers lovvveeee using git for this reason.

you might have to think more deeply about your versioning if

for time: if you think to yourself "where is that model?" or "oops, just downloaded the wrong model (again)" or 

different implementations: if you have a staging and production model. if you 

- keep track of your models
- choose what model is in production
    - you want a structure that you can quickly and easily change model versions 
- model registries (centralized location to store/version models) are great for versioning AND SHARING models with your team

:::

## version::vetiver

:::: {.columns}

::: {.column width="50%"}
```r
library(vetiver)
library(pins)

model_board <- board_temp(versioned = TRUE)
cars_lm <- lm(mpg ~ ., data = mtcars)

vetiver_model(cars_lm, "cars_linear")
model_board %>% vetiver_pin_write(v)
```
:::

::: {.column width="50%"}
```python
import vetiver
import pins

model_board = board_temp(versioned = True, allow_pickle_read = True)
cars_lm = linear_model.LinearRegression().fit(mtcars, mtcars["mpg"])

v = VetiverModel(cars_lm, model_name = "cars_linear", 
                 ptype_data = mtcars)
vetiver_pin_write(model_board, v)
```
:::

::::

![](images/vetiverhex.png){height="150"} ![](images/pinshex.png){height="150"}

## deploy

![](./images/happy.jpg)

places to deploy, not version

## deploy

- PMML

    - flexible in integration 
    - not flexibility in code

::: {.notes}
make them
XML is best known for displaying documents on the internet
    - baking cookies on an open flame (image)
    - models in XML (image?)
:::

## deploy

- SQL stored procedures

    - flexible in code
    - not less flexible in integration

![](images/tidypredicthex.png){width="150" height="150"}

::: {.notes}
- smaller
    - baking cookies in a waffle iron (image)
    - models saved in a database
    - works best if your workflow is centered around a database that you can easily interact with
    - not always as accessible to non-technical team members

:::

## deploy

- REST APIs
    - highly flexible in code, can deploy anything you write in R or Python
    - highly flexible in integration, POST/GET/QUERY to these endpoints

::: {.notes}

this can be a rest api on your computer, in the cloud

standard, easy

    - baking cookies in an oven (image)
    - models living in application interfaces
    - easy to use with other tools, so you keep the same workflow
    - often comes with visual documentation to be accessible to many different skill levels
    - interact in the browser to debug
    - straightforward to put inside docker containers

:::


## vetiver

:::: {.columns}

::: {.column width="50%"}
_in python_
```python
v = VetiverModel.from_pin(board, version = "3as8d")

api = VetiverAPI(v)
api.run()
```
:::

::: {.column width="50%"}
_in r_
```r
library(plumber)

pr() %>%
  vetiver_api(v)
```
:::

::::

![](images/vetiverhex.png){height="150"}

## vetiver

![](images/visualapi.png)

## monitor

![](images/burnt.jpg)

:::{.notes}
have a plan for how long your cookies are in the oven, but you have to keep an eye on them and adjust your plan if things aren't working out
:::

## monitor

- monitor your data
    - does your data from when you trained your model 2 months ago look the same as today?

## monitor

- monitor your data (data drift)
- monitor model performance (model drift)
    - models fail silently! and they can still run with no error, even if your accuracy is zero percent
        more detail here
    - i listened to waaaayyyy more jonas brothers in 2012 than i do now, and my spotify recommendation model has had to adapt!


## monitor

- monitor your data
- monitor model performance
- know what to do with degredation
    - back to model versioning!
    - retraining model?
    - new model type altogether?

## vetiver

:::: {.columns}

::: {.column width="50%"}
_in python_
```python
v = VetiverModel.from_pin(board, version = "3as8d")

api = VetiverAPI(v)
api.run()
```
:::

::: {.column width="50%"}
_in r_
```r
library(plumber)

pr() %>%
  vetiver_api(v)
```
:::

::::

## putting it all together

best practices:

- version your model
- deploy your model
- monitor your model

## putting it all together

best practices:

- version your model
- deploy your model
- monitor your model

... but also!

- responsible reporting
- data validation
- know the steps to update a model

## what now?

- think of what you need from MLOps
    - what is your strategy now? where can you add in best practices to make it better?

check out vetiver in PYTHON OR R in the open source or pro products lounge
