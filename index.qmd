---
format: 
    revealjs:
        slide-number: true
        theme: [default, style.scss]
        logo: images/vetiverhex.png
        width: 1600
        height: 900
---
##

::: {style="position: absolute; left: 480px; top: 200px; height: 525px; width: 1500px; background-color: #f3cbac; padding: 20px; padding-left: 50px; box-shadow: 15px 15px 0px 0px #a46848; border-radius: 5px;"}
[Demystifying MLOps]{style="font-size: 120px; font-weight: bold; line-height: 1em; margin: 0px"}

<br>

[Isabel Zimmerman, RStudio PBC]{style="font-size: 60px; font-weight: bold;"}

[rstudio::conf(2022)]{style="font-size: 50px;font-weight: bold;"}
:::

::: {.notes}
im here to demystfy mlops because machine learning operations are HARD i spent a lot of time with deploying models,,,

more importantly I LOVE BAKING
:::

##

![](images/happy.jpg){height="700" margin-left="700" margin-right="auto" fig-alt="cartoon cookie smiling"}

::: {.notes}
machine learning models are like chocolate chips...

while model development occurs in notebooks, the value of models often comes when they are integrated into a larger system
:::

## what is MLOps?

set of <u>practices</u> to _deploy_ and _maintain_ machine learning models in production **reliably** and **efficiently**

::: {.notes}
what are some MLOps practices?
:::

##

![](images/evolution_of_cookie.png)

::: {.notes}
- write down our recipe
- baking the dough
- making changes when things don't go as planned
:::

##

![](images/ml_ops_cycle.png)

::: {.notes}
- version
- deploy
- monitor

now, let's pause here for a moment-- MLOps is not a disjoint piece where data scientists can pass off models to IT, or whoever handles deployment. MLOps is part of the data science lifecycle.

There are lots of tools for the righthand side of this image--if you were just at Julia and Max's keynote, this might look familiar. Well, mostly familiar.
:::


## version
_how do we track and manage change?_

![](images/recipe_card.png){fig-alt="cartoon recipe card"}

::: {.notes}
try different flours, using salted or unsalted butter,

quick cautionary tale
:::

## version

`model`

. . .

`model_final`

. . .

`model_final_ACTUALLY`

. . .

`model_final_ACTUALLY_1`

::: {.notes}
lacks context
not scalable
:::
   
## version

versioning is useful to track changes across _time_, but it should also be for **different implementations**

::: {.notes}
you might have to think more deeply about your versioning if

for time: if you think to yourself "where is that model?" or "oops, just downloaded the wrong model (again)" or 

different implementations: if you have a staging and production model. if you 

- keep track of your models
- choose what model is in production
    - you want a structure that you can quickly and easily change model versions 
- model registries (centralized location to store/version models) are great for versioning AND SHARING models with your team

:::

## version::vetiver

:::: {.columns}

::: {.column width="50%"}
_in r_
```r
library(vetiver)
library(pins)

model_board <- board_temp()
```
:::

::: {.column width="50%"}
_in python_
```python
import vetiver
import pins

model_board = board_temp(
    allow_pickle_read = True)
```
:::

::::

![](images/pinshex.png){height=150px, fig-alt="pins hex sticker"}

## version::vetiver

:::: {.columns}

::: {.column width="50%"}
_in r_
```r
library(vetiver)
library(pins)

model_board <- board_temp()

v <- vetiver_model(model, "name")
```
:::

::: {.column width="50%"}
_in python_
```python
import vetiver
import pins

model_board = board_temp(
    allow_pickle_read = True)

v = VetiverModel(model, "name", 
    ptype_data = mtcars)
```
:::

::::

## version::vetiver

:::: {.columns}

::: {.column width="50%"}
_in r_
```r
library(vetiver)
library(pins)

model_board <- board_temp()

v <- vetiver_model(model, "name")

model_board %>% 
    vetiver_pin_write(v)
```
:::

::: {.column width="50%"}
_in python_
```python
import vetiver
import pins

model_board = board_temp(
    allow_pickle_read = True)

v = VetiverModel(model, "name", 
    ptype_data = mtcars)
vetiver_pin_write(model_board, v)
```
:::

::::

::: {.notes}
okay, well, how did that solve our problems with scale and context?
:::

## version::vetiver

:::: {.columns}

::: {.column width="50%"}
```python
model_board.pin_meta("name")
```
::: 

::: {.column width="50%"}

```r
model_board %>% pin_meta("name")
```
:::

::::

```
created: 20220719T142221Z
description: Scikit-learn  model
file: name.joblib
file_size: 1087
pin_hash: 4db397b49e7bff0b
title: 'name: a pinned LinearRegression object'
type: joblib
```
```
user:
  ptype: '{"cyl": 6.0, "disp": 160.0, "hp": 110.0, "drat": 3.9, "wt": 2.62, "qsec":
    16.46, "vs": 0.0, "am": 1.0, "gear": 4.0, "carb": 4.0}'
  required_pkgs:
  - vetiver
  - scikit-learn
```

::: {.notes}
okay, well, how did that solve our problems with scale and context?
:::

## deploy

![](images/happy.jpg){height="700" margin-left="700" margin-right="auto" fig-alt="cartoon cookie smiling"}

::: {.notes}
when building vetiver, we had to choose WHERE to deploy these models. there's a few options, so let's go on a quick journey to see how we made our decision.
:::

## deploy

- in XML (with PMML)
    - flexible in integration 
    - *not* flexible in modeling

![](images/fire.JPG){height="500" margin-left="700" margin-right="auto" fig-alt="cartoon cookie in this is fine fire meme"}

::: {.notes}

XML is best known for displaying documents on the internet
    - baking cookies on an open flame (image)
    - models in XML (image?)
:::

## deploy

- ~~in XML (with PMML)~~
- in databases (with SQL stored procedures)

    - flexible in modeling
    - *not* flexible in integration

![](images/waffle.png){height="400" margin-left="700" margin-right="auto" fig-alt="cartoon cookie with waffle iron pattern"}

::: {.notes}
- smaller
    - baking cookies in a waffle iron (image)
    - models saved in a database
    - works best if your workflow is centered around a database that you can easily interact with
    - not always as accessible to non-technical team members

:::

## deploy

- ~~in XML (with PMML)~~
- ~~in databases (with SQL stored procedures)~~
- in an API (with RESTful APIs)

    - highly flexible in modeling
    - highly flexible in integration

![](images/ovenbffs.png){height="350" margin-left="700" margin-right="auto" fig-alt="cartoon cookie holding hands with cartoon oven"}

::: {.notes}

this can be a rest api on your computer, in the cloud ie, SAGEMAKER, ETC, if you're more interested in this, James Blair is hosting ____

if youre interested in seeing this in RSConnnect, gagan and xu fei are talking 
standard, easy
can deploy anything you write in R or Python
POST/GET/QUERY to these endpoints

    - baking cookies in an oven (image)
    - models living in application interfaces
    - easy to use with other tools, so you keep the same workflow
    - often comes with visual documentation to be accessible to many different skill levels
    - interact in the browser to debug
    - straightforward to put inside docker containers

:::


## vetiver

:::: {.columns}

::: {.column width="50%"}
_in python_
```python
api = VetiverAPI(v)
api.run()
```
:::

::: {.column width="50%"}
_in r_
```r
library(plumber)

pr() %>%
  vetiver_api(v)
```
:::

::::

## {background-video="images/apidocs.mp4"}

## monitor

![](images/burnt.jpg){height="700" margin-left="700" margin-right="auto" fig-alt="cartoon cookie, slightly burnt"}

:::{.notes}
have a plan for how long your cookies are in the oven, but you have to keep an eye on them and adjust your plan if things aren't working out
:::

## monitor

- monitor for data drift


:::{.notes}
does your data from when you trained your model 2 months ago look the same as today?
:::

## monitor

- monitor for data drift
- monitor for model drift


:::{.notes}
- models fail silently! and they can still run with no error, even if your accuracy is zero percent
    more detail here
- i listened to waaaayyyy more jonas brothers in 2012 than i do now, and my spotify recommendation model has had to adapt!
:::

## monitor

- monitor for data drift
- monitor for model drift
- know what to do when things go wrong


:::{.notes}
if performance is declining, 
    - back to model versioning!
    - retraining model?
    - new model type altogether?
:::

## vetiver

:::: {.columns}

::: {.column width="50%"}
_in python_
```python
metrics = vetiver.compute_metrics(
    new_data, 
    "date_col", 
    timedelta(weeks = 1), 
    metric_set, 
    "mpg", 
    "preds"
    )
```
:::

::: {.column width="50%"}
_in r_
```r
metrics <-
    augment(v, new_data = new) %>%
    vetiver_compute_metrics(
        date_col, 
        "week", 
        mpg, 
        .pred
        )
```
:::

::::

## vetiver

:::: {.columns}

::: {.column width="50%"}
_in python_
```python
# compute, then ... 

vetiver.pin_metrics(
    model_board, 
    metrics, 
    "metrics_pin_name", 
    overwrite = True
    )
```
:::

::: {.column width="50%"}
_in r_
```r
# compute, then ... 

model_board %>%
    vetiver_pin_metrics(
        metrics, 
        "metrics_pin_name", 
        overwrite = TRUE
        )
```
:::

::::


## vetiver

:::: {.columns}

::: {.column width="50%"}
_in python_
```python
# compute and pin, then ...

vetiver.plot_metrics(metrics)
```
:::

::: {.column width="50%"}
_in r_
```r
# compute and pin, then ...

vetiver_plot_metrics(metrics)
```
:::

::::

![](images/monitor.png){fig-alt="line chart showing model performance metrics over time" class = "center"}

## putting it all together

best practices:

- **version** your model
- _deploy_ your model
- <u>monitor</u> your model

. . .

but also!

- responsible reporting
- data validation
- more!


## 
![](images/final.png){fig-alt="cartoon cookies holding hands, with the last cookie in thought about the MLOps cycle"}

::: {.notes}
must be end of our time, our cookies are taking a bow...

challenge you think of what your own data science workflow...where can you add in MLOps best practices to make it better?

check out vetiver in PYTHON OR R in the open source or pro products lounge
---
what's next for vetiver?
taking a nap!
building out workflows for cloud

what models are supported?

explainability?

:::

